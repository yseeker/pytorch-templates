{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "template_Tez.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1esdPQUe7vCl97dVfU9Ns16iDz_vUHTzt",
      "authorship_tag": "ABX9TyMmNilBQou5y18bs6ridBBf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yseeker/pytorch-templates/blob/main/template_Tez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xDJzJCP7G-O",
        "outputId": "c3c65480-7c91-4e05-84aa-ad787a792e57"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jul  2 22:28:39 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iU9JpX2_4NK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ec2246-3725-440d-b5f3-3398c74c26b0"
      },
      "source": [
        "!pip install gwpy --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 13.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.3MB 47.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 48.6MB/s \n",
            "\u001b[?25h  Building wheel for ligo-segments (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fdlUr2O_5Ei"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb\n",
        "from pathlib import Path\n",
        "class CFG:\n",
        "    project_name = 'project name'\n",
        "    pretrained_model_name = 'efficientnetv2_rw_s'\n",
        "    lr = 5e-4\n",
        "    batch_size= 128\n",
        "    wandb_note = f'bs{batch_size}_adamW_default_lr{lr}'\n",
        "    pretrained = True\n",
        "    prettained_path = '../input/timm_weight/efficientnet_v2s_ra2_288-a6477665.pth'\n",
        "    input_channels = 1\n",
        "    out_dim = 1\n",
        "    colab_or_kaggle = 'colab'\n",
        "    wandb_exp_name = f'{pretrained_model_name}_{colab_or_kaggle}_{wandb_note}'\n",
        "    monitor = 'valid_roc_auc'\n",
        "    epochs = 3\n",
        "    num_of_fold = 5\n",
        "    seed = 42\n",
        "    num_workers = 8\n",
        "    fp16 = True\n",
        "    checkpoint_path = ''\n",
        "    patience_mode = 'max'\n",
        "    patience = 10\n",
        "    delta = 0.001\n",
        "    mixup_alpha = 1.0\n",
        "    benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxLtP1LWXMWX"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/kaggle/input/***/data.csv\" \"/content\"\n",
        "!unzip \"/content/drive/MyDrive/kaggle/input/***.zip\" -d \"/content/train\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTPtXCdJE3wK"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import albumentations as A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w1ohCx7FD2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd259e6-8782-470f-863a-8997ebda34ee"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/kaggle/working\")\n",
        "!pip install git+https://github.com/yseeker/tez_custom\n",
        "#!pip install timm\n",
        "#tez_path = '../input/tez-lib'\n",
        "#efnet_path = '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master'\n",
        "timm_path = '/content/drive/My Drive/kaggle/input/pytorch-image-models-master'\n",
        "#sys.path.append(tez_path)\n",
        "#sys.path.append(efnet_path)\n",
        "sys.path.append(timm_path)\n",
        "\n",
        "#from efficientnet_pytorch import model as enet\n",
        "import tez\n",
        "from tez.datasets import ImageDataset\n",
        "from tez.callbacks import EarlyStopping\n",
        "import timm\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/yseeker/tez_custom\n",
            "  Cloning https://github.com/yseeker/tez_custom to /tmp/pip-req-build-bdt8o694\n",
            "  Running command git clone -q https://github.com/yseeker/tez_custom /tmp/pip-req-build-bdt8o694\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tez==0.1.4) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->tez==0.1.4) (3.7.4.3)\n",
            "Building wheels for collected packages: tez\n",
            "  Building wheel for tez (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tez: filename=tez-0.1.4-cp37-none-any.whl size=16331 sha256=36515423fca37f1d63415ee4fc0766b41802bee19854ed0fc810065ede2efdc9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qc81533e/wheels/e5/10/9b/26e6bbb22ca448a97284deb3404335e6dfdd30320c1e66b699\n",
            "Successfully built tez\n",
            "Installing collected packages: tez\n",
            "Successfully installed tez-0.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqHLcYJJ_9KH"
      },
      "source": [
        "train_aug = A.Compose(\n",
        "    [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.ShiftScaleRotate(p=0.5,\n",
        "                           shift_limit = 0.2, \n",
        "                           scale_limit=0.2,\n",
        "                           rotate_limit=30, \n",
        "                           border_mode = cv2.BORDER_REPLICATE),\n",
        "        A.OneOf([\n",
        "            A.MedianBlur(p=0.3),\n",
        "            A.MotionBlur(p=0.3)\n",
        "        ]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "df = pd.read_csv('/content/training_labels.csv')\n",
        "df['img_path'] = df['id'].apply(\n",
        "    lambda x: f\"/content/train/{x}.npy\"\n",
        ")\n",
        "\n",
        "X = df.img_path.values\n",
        "Y = df.target.values\n",
        "\n",
        "skf = StratifiedKFold(n_splits = CFG.num_of_fold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSCUPDaxva3l"
      },
      "source": [
        "def sigmoid(gamma):\n",
        "    if gamma < 0:\n",
        "        return 1 - 1 / (1 + math.exp(gamma))\n",
        "    return 1 / (1 + math.exp(-gamma))\n",
        "\n",
        "# define vectorized sigmoid\n",
        "sigmoid_v = np.vectorize(sigmoid)\n",
        "\n",
        "def set_seed(seed = 0):\n",
        "    np.random.seed(seed)\n",
        "    random_state = np.random.RandomState(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    return random_state\n",
        "\n",
        "def mixup_data(inputs, targets, alpha=1.0):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "    batch_size = inputs.size()[0]\n",
        "    index = torch.randperm(batch_size)\n",
        "    mixed_inputs = lam * inputs + (1 - lam) * inputs[index, :]\n",
        "    targets_a, targets_b = targets, targets[index]\n",
        "    \n",
        "    return mixed_inputs, targets_a, targets_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, outputs, targets_a, targets_b, lam):\n",
        "    return lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6ULGIlopdyk"
      },
      "source": [
        "class ClassificationDataset():\n",
        "    def __init__(self, image_paths, targets, transform = None): \n",
        "        self.image_paths = image_paths\n",
        "        self.targets = targets\n",
        "        self.transform = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, item): \n",
        "        targets = self.targets[item]\n",
        "        image = np.load(self.image_paths[item])\n",
        "        image = image.astype(np.float32)[np.newaxis, ]\n",
        "\n",
        "        return {\n",
        "            \"image\": torch.tensor(image, dtype=torch.float),\n",
        "            \"targets\": torch.tensor(targets, dtype=torch.float),\n",
        "        }\n",
        "\n",
        "class CustomNN(tez.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(CFG.pretrained_model_name, \n",
        "                                       pretrained = CFG.pretrained, \n",
        "                                       in_chans = CFG.input_channels)\n",
        "        if not CFG.pretrained: self.model.load_state_dict(torch.load(CFG.pretrained_path))\n",
        "        self.model.classifier = nn.Linear(self.model.classifier.in_features, CFG.out_dim)\n",
        "            \n",
        "        self.criterion =  nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "    def forward(self, image, targets = None):\n",
        "        outputs = self.model(image)\n",
        "        \n",
        "        if targets is not None:\n",
        "            loss = self.criterion(outputs.flatten(), targets)\n",
        "            metrics = self.monitor_metrics(outputs, targets)\n",
        "            return outputs, loss, metrics\n",
        "        return outputs, None, None\n",
        "\n",
        "    def epoch_metrics(self, outputs, targets):\n",
        "        preds = sigmoid_v(outputs)\n",
        "        roc_auc = metrics.roc_auc_score(targets, preds)\n",
        "        return roc_auc\n",
        "\n",
        "    def monitor_metrics(self, outputs, targets):\n",
        "        preds = outputs.sigmoid().cpu().detach().numpy()\n",
        "        targets = targets.cpu().detach().numpy()\n",
        "        if len(np.unique(targets)) > 1: \n",
        "            roc_auc = metrics.roc_auc_score(targets, preds)\n",
        "        else: roc_auc = 0.5\n",
        "        return {\"roc_auc\": roc_auc}\n",
        "\n",
        "    def configure_optimizer(self):\n",
        "        opt = torch.optim.AdamW(self.parameters(), lr=CFG.lr, weight_decay=0.01)\n",
        "        #opt = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
        "        return opt\n",
        "    \n",
        "    def configure_scheduler(self):\n",
        "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
        "        )\n",
        "        return sch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goz6Y-xA_0AK"
      },
      "source": [
        "models = []\n",
        "for fold_cnt, (train_index, test_index) in enumerate(skf.split(X, Y)):\n",
        "    train_images, valid_images = X[train_index], X[test_index]\n",
        "    train_targets, valid_targets = Y[train_index], Y[test_index]\n",
        "\n",
        "    train_dataset = ClassificationDataset(\n",
        "        image_paths=train_images, \n",
        "        targets=train_targets, \n",
        "        transform = train_aug\n",
        "    )\n",
        "    valid_dataset = ClassificationDataset(\n",
        "        image_paths=valid_images, \n",
        "        targets=valid_targets, \n",
        "        transform = None\n",
        "    )\n",
        "    model = CustomNN()\n",
        "\n",
        "    es = EarlyStopping(\n",
        "        monitor=CFG.monitor, \n",
        "        model_path=CFG.checkpoint_path+f'{CFG.pretrained_model_name}_{fold_cnt}fold_{CFG.wandb_note}.cpt', \n",
        "        patience= CFG.patience, \n",
        "        mode=CFG.patience_mode,\n",
        "        delta = CFG.delta\n",
        "    )\n",
        "    model.fit(\n",
        "        cfg = CFG,\n",
        "        train_dataset = train_dataset,\n",
        "        valid_dataset = valid_dataset,\n",
        "        valid_targets = valid_targets,\n",
        "        train_bs=CFG.batch_size,\n",
        "        valid_bs=CFG.batch_size,\n",
        "        epochs=CFG.epochs,\n",
        "        callbacks=[es],\n",
        "        n_jobs = CFG.num_workers,\n",
        "        fp16=CFG.fp16,\n",
        "        benchmark = CFG.benchmark\n",
        "    )\n",
        "    models.append(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfr_uq5ADJGf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zUA3vwfDJQ7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHCy9RfvsG6c"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/kaggle/input/***/sample_submission.csv\" \"/content\"\n",
        "!unzip \"/content/drive/MyDrive/kaggle/input/***.zip\" -d \"/content/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLJJW08RHlRi"
      },
      "source": [
        "submission = pd.read_csv('/content/sample_submission.csv')\n",
        "submission['img_path'] = submission['id'].apply(\n",
        "    lambda x: f'/content/test/{x}.npy'\n",
        ")\n",
        "test_dataset = ClassificationDataset(\n",
        "    image_paths=submission.img_path.values, \n",
        "    targets=submission.target.values, \n",
        "    transform = train_aug\n",
        ")\n",
        "\n",
        "final_preds = None\n",
        "num_of_ave = 5\n",
        "outs = []\n",
        "for i, model in enumerate(models):\n",
        "    model.save(f'/content/{i}fold.cpt')\n",
        "    for j in range(num_of_ave):\n",
        "        preds = model.predict(test_dataset, batch_size=128, n_jobs=-1)\n",
        "        temp_preds = None\n",
        "        for p in preds:\n",
        "            if temp_preds is None:\n",
        "                temp_preds = p\n",
        "            else:\n",
        "                temp_preds = np.vstack((temp_preds, p))\n",
        "        if final_preds is None:\n",
        "            final_preds = temp_preds\n",
        "        else:\n",
        "            final_preds += temp_preds\n",
        "    final_preds = final_preds/num_of_ave\n",
        "    out = sigmoid_v(final_preds)\n",
        "    outs.append(out)\n",
        "pred = np.mean(np.array(outs), axis=0)\n",
        "submission.target = pred\n",
        "submission.drop(['img_path'], axis=1, inplace=True)\n",
        "submission.to_csv('/content/submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSIXouwoVPlh"
      },
      "source": [
        "import os\n",
        "import json\n",
        "f = open(\"/content/drive/My Drive/kaggle/kaggle.json\", 'r')\n",
        "json_data = json.load(f) #JSON形式で読み込む\n",
        "os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
        "os.environ['KAGGLE_KEY'] = json_data['key']\n",
        "#os.chdir(\"/content/drive/My Drive/kaggle/working\")\n",
        "\n",
        "!kaggle competitions submit -c titanic -f submission.csv -m 'submit!!'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}