{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "template-lightning.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMr/PR0WSnFIyZ38V99Zaas",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yseeker/pytorch_templates/blob/main/template_lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-vTHxq1a9aY"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDx_CEXpbKaJ"
      },
      "source": [
        "!pip install gwpy --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGDnu_J9bOow"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb\n",
        "\n",
        "class CFG:\n",
        "    project_name = 'project name'\n",
        "    pretrained_model_name = 'efficientnetv2_rw_s'\n",
        "    pretrained = True\n",
        "    prettained_path = '../input/timm_weight/efficientnet_b0_ra-3dd342df.pth'\n",
        "    input_channels = 3\n",
        "    out_dim = 1\n",
        "    wandb_note = ''\n",
        "    colab_or_kaggle = 'kaggle'\n",
        "    wandb_exp_name = f'{pretrained_model_name}_{colab_or_kaggle}_{wandb_note}'\n",
        "    batch_size= 16\n",
        "    epochs = 5\n",
        "    num_of_fold = 5\n",
        "    seed = 42\n",
        "    patience = 3\n",
        "    delta = 0.002\n",
        "    num_workers = 8\n",
        "    fp16 = True\n",
        "    checkpoint_path = ''\n",
        "    patience_mode = 'max'\n",
        "    patience = 3\n",
        "    delta = 0.002\n",
        "    mixup_alpha = 1.0\n",
        "    gpus = 1\n",
        "    amp_backend = 'native'\n",
        "    precision = 32\n",
        "    enable_benchmarking = True\n",
        "    auto_find_lr = False\n",
        "    lr = 5e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOrLci2jbTpy"
      },
      "source": [
        "# load data\n",
        "%%capture\n",
        "# !unzip \"/content/drive/MyDrive/kaggle/input/project/data.zip\" -d \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8quDc4zbVrM"
      },
      "source": [
        "import os\n",
        "import json\n",
        "f = open(\"/content/drive/My Drive/kaggle/kaggle.json\", 'r')\n",
        "json_data = json.load(f) #JSON形式で読み込む\n",
        "os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
        "os.environ['KAGGLE_KEY'] = json_data['key']\n",
        "os.chdir(\"/content/drive/My Drive/kaggle/working\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh4tRqHSbWmS"
      },
      "source": [
        "!pip install wandb\n",
        "!pip install pytorch_lightning\n",
        "!pip install timm\n",
        "import collections\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau, OneCycleLR\n",
        "from torch.optim.optimizer import Optimizer\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import seed_everything\n",
        "from pytorch_lightning.metrics.functional import accuracy, f1, auroc\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping,LearningRateMonitor\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "import timm\n",
        "import albumentations as A\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrmphG2lbgzr"
      },
      "source": [
        "df = pd.read_csv('../input/***/train_labels.csv')\n",
        "df['img_path'] = df['id'].apply(\n",
        "    lambda x: f'../input/***train/{x[0]}/{x}.npy'\n",
        ")\n",
        "X = df.img_path.values\n",
        "Y = df.target.values\n",
        "skf = StratifiedKFold(n_splits = CFG.num_of_fold)\n",
        "\n",
        "def set_seed(seed = 0):\n",
        "    np.random.seed(seed)\n",
        "    random_state = np.random.RandomState(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    return random_state\n",
        "set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3z4RQZDbisH"
      },
      "source": [
        "class ClassificationDataset():\n",
        "    def __init__(self, image_paths, targets, transform = None): \n",
        "        self.image_paths = image_paths\n",
        "        self.targets = targets\n",
        "        self.transform = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, item): \n",
        "        targets = self.targets[item]\n",
        "        image1 = np.load(self.image_paths[item])[::2].astype(np.float32)\n",
        "        image = np.vstack(image1).transpose((1, 0))\n",
        "\n",
        "        image = ((image - np.mean(image, axis=1, keepdims=True)) / np.std(image, axis=1, keepdims=True))\n",
        "        image = ((image - np.mean(image, axis=0, keepdims=True)) / np.std(image, axis=0, keepdims=True))\n",
        "    \n",
        "        image = image.astype(np.float32)[np.newaxis, ]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        return {'image' : torch.tensor(image, dtype=torch.float), \n",
        "                'targets' : torch.tensor(targets, dtype=torch.float)}\n",
        "\n",
        "\n",
        "class LitData(pl.LightningDataModule):\n",
        "    def __init__(self, train_images, train_targets, valid_images, valid_targets):\n",
        "        super().__init__()\n",
        "        self.train_images = train_images\n",
        "        self.train_targets = train_targets\n",
        "        self.valid_images = valid_images\n",
        "        self.valid_targets = valid_targets\n",
        "    \n",
        "    def setup(self,stage=None):\n",
        "        self.train_aug = A.Compose(\n",
        "            [\n",
        "                A.Resize(p = 1, height = 512, width = 512),\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.VerticalFlip(p=0.5),\n",
        "                A.ShiftScaleRotate(p=0.5, \n",
        "                                scale_limit=0.02,\n",
        "                                rotate_limit=10, \n",
        "                                border_mode = cv2.BORDER_REPLICATE),\n",
        "                A.MotionBlur(p=0.5),\n",
        "            ]\n",
        "        )\n",
        "        self.train_dataset = ClassificationDataset(\n",
        "            image_paths=self.train_images, \n",
        "            targets=self.train_targets, \n",
        "            transform = None\n",
        "        )\n",
        "        self.valid_dataset = ClassificationDataset(\n",
        "            image_paths=self.valid_images, \n",
        "            targets=self.valid_targets, \n",
        "            transform = None\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "                    self.train_dataset,\n",
        "                    batch_size=CFG.batch_size,\n",
        "                    shuffle= True,\n",
        "                    num_workers=CFG.num_workers,\n",
        "                    pin_memory = True\n",
        "                 )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "                    self.valid_dataset,\n",
        "                    batch_size=CFG.batch_size,\n",
        "                    shuffle= False,\n",
        "                    num_workers=CFG.num_workers,\n",
        "                    pin_memory=True\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxclF-wRbshI"
      },
      "source": [
        "class LitNN(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(CFG.pretrained_model_name, \n",
        "                                       pretrained = CFG.pretrained, \n",
        "                                       in_chans = CFG.input_channels)\n",
        "        if not CFG.pretrained: \n",
        "            self.model.load_state_dict(torch.load(CFG.pretrained_path))\n",
        "        self.model.classifier = nn.Linear(self.model.classifier.in_features, CFG.out_dim)\n",
        "        self.conv1 = nn.Conv2d(1, 3, \n",
        "                               kernel_size=3, \n",
        "                               stride=1, \n",
        "                               padding=3, \n",
        "                               bias=False)\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.lr = CFG.lr\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        outputs = self.model(x)\n",
        "        return outputs\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, targets = batch['image'], batch['targets']\n",
        "        preds = self(inputs)\n",
        "        loss = self.criterion(preds, targets.view(-1, 1))\n",
        "        data = {\"loss\": loss, \"preds\": preds, \"targets\": targets}\n",
        "        self.log('train/loss', loss.cpu().detach().numpy(), prog_bar=False, logger=True)\n",
        "        self.log('lr',self.optimizer.param_groups[0]['lr'], prog_bar=False, logger=True)\n",
        "        self.calculate_metrics('train_step',\n",
        "                               loss.cpu().detach().numpy(),\n",
        "                               preds.cpu().detach().numpy(),\n",
        "                               targets.cpu().detach().numpy())\n",
        "        return data\n",
        "\n",
        "    def training_epoch_end(self, training_step_outputs):\n",
        "        self.calculate_metrics_epoch_end('train_epoch', training_step_outputs)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        inputs, targets = batch['image'], batch['targets']\n",
        "        preds = self(inputs)\n",
        "        loss = self.criterion(preds, targets.view(-1, 1))\n",
        "        data = {\"loss\": loss, \"preds\": preds, \"targets\": targets}\n",
        "        self.calculate_metrics('valid_step',\n",
        "                               loss.cpu().detach().numpy(), \n",
        "                               preds.cpu().detach().numpy(),\n",
        "                               targets.cpu().detach().numpy())\n",
        "        return data\n",
        "      \n",
        "    def validation_epoch_end(self, validation_step_outputs):\n",
        "        self.calculate_metrics_epoch_end('valid_epoch', validation_step_outputs)\n",
        "        \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        inputs = batch['image']\n",
        "        preds_batch = self(inputs)\n",
        "        return preds_batch\n",
        "    \n",
        "    def test_epoch_end(self, test_step_outputs):\n",
        "        preds = torch.cat(outputs).detach().cpu().numpy()\n",
        "        df = pd.DataFrame({'target':y_preds})\n",
        "        N = len(glob.glob('submission*.csv'))\n",
        "        df.target.to_csv(f'submission{N}.csv')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        self.optimizer = Adam(self.parameters(), lr=self.lr)\n",
        "        self.scheduler = CosineAnnealingWarmRestarts(\n",
        "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1)\n",
        "        return [self.optimizer], [self.scheduler]\n",
        "\n",
        "    def calculate_metrics(self, stage, loss, preds, targets):\n",
        "        try :roc_auc = metrics.roc_auc_score(targets, preds)\n",
        "        except : roc_auc = 1.1\n",
        "        self.log_dict({f'{stage}/metric' : roc_auc}, prog_bar= True, logger=True)\n",
        "        if stage == 'valid_epoch': print('valid_epoch : ', roc_auc)\n",
        "\n",
        "    def calculate_metrics_epoch_end(self, stage, outputs):\n",
        "        data = {}\n",
        "        for output in outputs:\n",
        "            for key in output.keys():\n",
        "                if key not in data: data[key] = []\n",
        "                else: \n",
        "                    data[key].append(output[key].cpu().detach().numpy())\n",
        "        for key in data.keys():\n",
        "            if key != 'loss': \n",
        "                data[key] = np.concatenate(data[key])\n",
        "        self.calculate_metrics(stage, **data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgTdJkeRcDnk"
      },
      "source": [
        "for fold_cnt, (train_index, test_index) in enumerate(skf.split(X, Y), 1):\n",
        "    train_images, valid_images = X[train_index], X[test_index]\n",
        "    train_targets, valid_targets = Y[train_index], Y[test_index]\n",
        "\n",
        "    data_module = LitData(train_images, train_targets, valid_images, valid_targets)\n",
        "    model = LitNN()\n",
        "\n",
        "#     cpt = ModelCheckpoint(\n",
        "#         save_top_k=CFG.epochs,\n",
        "#         verbose=True,\n",
        "#         monitor='valid/roc_auc',\n",
        "#         mode=CFG.patience_mode\n",
        "#     )\n",
        "\n",
        "    es = EarlyStopping(\n",
        "        monitor='valid/roc_auc',\n",
        "        mode=CFG.patience_mode,\n",
        "        patience= CFG.patience)\n",
        "    \n",
        "#     lr_monitor = LearningRateMonitor(\n",
        "#         logging_interval='step')\n",
        "\n",
        "    wandb_logger = WandbLogger(\n",
        "        name=CFG.wandb_exp_name,\n",
        "        project= CFG.project_name, \n",
        "        offline=False, \n",
        "        log_model=False\n",
        "    )\n",
        "\n",
        "    Trainer = pl.Trainer(\n",
        "        #checkpoint_callback=cpt,\n",
        "        #callbacks=[es],\n",
        "        max_epochs=CFG.epochs,\n",
        "        amp_backend = CFG.amp_backend,\n",
        "        gpus=CFG.gpus,\n",
        "        precision=CFG.precision,\n",
        "        logger=wandb_logger,\n",
        "        auto_lr_find=CFG.auto_find_lr\n",
        "    )\n",
        "    if CFG.auto_find_lr:\n",
        "        Trainer.tune(model, datamodule=data_module)\n",
        "        print('best initial lr : ', model.lr)\n",
        "    Trainer.fit(model, data_module)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}