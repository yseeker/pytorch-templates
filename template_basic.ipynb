{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "template_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1urRIQRoh9-gWVmm9KTWjExME5kVcjBWv",
      "authorship_tag": "ABX9TyPjkYHifgZr2cVrk/1zCfNv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yseeker/pytorch_templates/blob/main/template_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xDJzJCP7G-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57830736-66da-4ea8-fbca-343c0b1ed6f4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul  1 01:15:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FgOZvp9Twko"
      },
      "source": [
        "!pip install gwpy --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONHqlHq6TzWe"
      },
      "source": [
        "%%capture\n",
        "class CFG:\n",
        "    project_name = 'your project name'\n",
        "    pretrained_model_name = 'efficientnetv2_rw_s'\n",
        "    pretrained = True\n",
        "    prettained_path = '../input/timm_weight/efficientnet_b0_ra-3dd342df.pth'\n",
        "    mixup_alpha = 0.5\n",
        "    lr = 1.0e-6\n",
        "    batch_size= 16\n",
        "    wandb_note = f'tawara_bs{batch_size}_adamW_default_lr{lr}_alpha{mixup_alpha}'\n",
        "    input_channels = 3\n",
        "    out_dim = 1\n",
        "    colab_or_kaggle = 'colab'\n",
        "    wandb_exp_name = f'{pretrained_model_name}_{colab_or_kaggle}_{wandb_note}'\n",
        "    epochs = 60\n",
        "    num_of_fold = 5\n",
        "    seed = 42\n",
        "    patience = 3\n",
        "    delta = 0.002\n",
        "    num_workers = 8\n",
        "    fp16 = True\n",
        "    checkpoint_path = ''\n",
        "    patience_mode = 'max'\n",
        "    patience = 3\n",
        "    delta = 0.002"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAD1kL_xEzUj"
      },
      "source": [
        "# Kaggle\n",
        "import os\n",
        "import json\n",
        "f = open(\"/content/drive/My Drive/kaggle/kaggle.json\", 'r')\n",
        "json_data = json.load(f) #JSON形式で読み込む\n",
        "os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
        "os.environ['KAGGLE_KEY'] = json_data['key']\n",
        "os.chdir(\"/content/drive/My Drive/kaggle/working\")\n",
        "os.chdir(\"/content\") #content 直下"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTPtXCdJE3wK"
      },
      "source": [
        "%%capture\n",
        "!pip install --upgrade albumentations\n",
        "!pip install --upgrade wandb\n",
        "!pip install --!pip install colabcode --upgrade\n",
        "# ColabCode()\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "from pathlib import Path\n",
        "#from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import datetime\n",
        "import psutil\n",
        "import gc\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import timm\n",
        "\n",
        "import wandb\n",
        "from colabcode import ColabCode\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w1ohCx7FD2R"
      },
      "source": [
        "#If internet is off\n",
        "tez_path = '../input/tez-lib'\n",
        "efnet_path = '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master'\n",
        "timm_path = '../input/pytorch-image-models-master'\n",
        "sys.path.append(tez_path)\n",
        "sys.path.append(efnet_path)\n",
        "sys.path.append(timm_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6ULGIlopdyk"
      },
      "source": [
        "# Utils\n",
        "def set_seed(seed = 0):\n",
        "    np.random.seed(seed)\n",
        "    random_state = np.random.RandomState(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    return random_state\n",
        "\n",
        "def mixup_data(inputs, targets, alpha=1.0):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "    batch_size = inputs.size()[0]\n",
        "    index = torch.randperm(batch_size)\n",
        "    mixed_inputs = lam * inputs + (1 - lam) * inputs[index, :]\n",
        "    targets_a, targets_b = targets, targets[index]\n",
        "    \n",
        "    return mixed_inputs, targets_a, targets_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, outputs, targets_a, targets_b, lam):\n",
        "    return lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i88MLFLA0gvh"
      },
      "source": [
        "class AverageMeter:\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIgBPBdWGYLR"
      },
      "source": [
        "train_aug = A.Compose(\n",
        "    [\n",
        "        A.Resize(p = 1.0, height = 512, width = 512),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.ShiftScaleRotate(p=0.5,\n",
        "                           shift_limit = 0.2, \n",
        "                           scale_limit=0.2,\n",
        "                           rotate_limit=30, \n",
        "                           border_mode = cv2.BORDER_REPLICATE),\n",
        "        A.RandomResizedCrop(\n",
        "            p = 1.0,\n",
        "            height = 320,\n",
        "            width = 320,\n",
        "            scale = [0.9, 1.0]\n",
        "        ),\n",
        "        A.OneOf([\n",
        "            A.MedianBlur(p=0.3),\n",
        "            A.MotionBlur(p=0.3)\n",
        "        ]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "df = pd.read_csv('../input/***/train_labels.csv')\n",
        "df['img_path'] = df['id'].apply(\n",
        "    lambda x: f'../input/***/train/{x[0]}/{x}.npy'\n",
        ")\n",
        "X = df.img_path.values\n",
        "Y = df.target.values\n",
        "skf = StratifiedKFold(n_splits = CFG.num_of_fold)\n",
        "\n",
        "class ClassificationDataset():\n",
        "    def __init__(self, image_paths, targets, transform = None): \n",
        "        self.image_paths = image_paths\n",
        "        self.targets = targets\n",
        "        self.transform = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, item): \n",
        "        image = cv2.imread(self.image_paths[item])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        if self.augmentations is not None:\n",
        "            augmented = self.augmentations(image=image)\n",
        "            image = augmented[\"image\"]\n",
        "\n",
        "        image_tensor = torch.tensor(image)\n",
        "        return image_tensor, torch.tensor(targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DYCYENwjwvj"
      },
      "source": [
        "class BasicNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(CFG.pretrained_model_name, \n",
        "                                       pretrained = CFG.pretrained, \n",
        "                                       in_chans = CFG.input_channels)\n",
        "        if not CFG.pretrained: self.model.load_state_dict(torch.load(CFG.pretrained_path))\n",
        "        self.model.classifier = nn.Linear(self.model.classifier.in_features, CFG.out_dim)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        outputs = self.model(inputs)\n",
        "        return outputs\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        train_dataset,\n",
        "        valid_dataset = None,\n",
        "        train_batchsize = 16,\n",
        "        valid_batchsize = 16,\n",
        "        valid_targets = None,\n",
        "        num_workers = 4,\n",
        "        fp16 = True,\n",
        "        multiple_GPU = False,\n",
        "        determinstic = True,\n",
        "        benchmark = False\n",
        "    ):\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        self.model = model\n",
        "        self.model.to(self.device)\n",
        "        self.valid_targets = valid_targets\n",
        "\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.optimizer = self.configure_optimizer()\n",
        "        self.scheduler_after_step = self.configure_scheduler_after_step()\n",
        "        self.scheduler_after_epoch = self.configure_scheduler_after_epoch()\n",
        "\n",
        "        torch.backends.cudnn.deterministic = determinstic\n",
        "        torch.backends.cudnn.benchmark = benchmark\n",
        "        self.fp16 = fp16\n",
        "        self.scaler = torch.cuda.amp.GradScaler() \n",
        "        \n",
        "        if num_workers == -1: num_workers = psutil.cpu_count()\n",
        "        self.multiple_GPU = multiple_GPU\n",
        "        if multiple_GPU and torch.cuda.device_count() > 1:\n",
        "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "            self = nn.DataParallel(self)\n",
        "        \n",
        "        self.train_loader = torch.utils.data.DataLoader(\n",
        "            dataset = train_dataset, \n",
        "            batch_size = train_batchsize,\n",
        "            shuffle=True, \n",
        "            num_workers= num_workers,\n",
        "            drop_last = True,\n",
        "            pin_memory = True\n",
        "        )\n",
        "        self.valid_loader = torch.utils.data.DataLoader(\n",
        "            dataset = valid_dataset, \n",
        "            batch_size=valid_batchsize,\n",
        "            shuffle=False, \n",
        "            num_workers = num_workers,\n",
        "            drop_last = False,\n",
        "            pin_memory = True\n",
        "        )\n",
        "\n",
        "    def _init_wandb(self, cfg):\n",
        "        hyperparams = {\n",
        "            'batch_size' : cfg.batch_size,\n",
        "            'epochs' : cfg.epochs\n",
        "        }\n",
        "        wandb.init(\n",
        "            config = hyperparams,\n",
        "            project= cfg.project_name,\n",
        "            name=cfg.wandb_exp_name,\n",
        "        )\n",
        "        wandb.watch(self.model)\n",
        "\n",
        "    def configure_optimizer(self):\n",
        "        opt = torch.optim.Adam(self.model.parameters(), lr=CFG.lr)\n",
        "        return opt\n",
        "    \n",
        "    def configure_scheduler_after_step(self):\n",
        "        sch = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            optimizer = self.optimizer,\n",
        "            epochs = CFG.epochs,\n",
        "            steps_per_epoch = 2508,\n",
        "            max_lr = 5.0e-4,\n",
        "            pct_start = 0.1,\n",
        "            anneal_strategy = 'cos',\n",
        "            div_factor = 1.0e+3,\n",
        "            final_div_factor = 1.0e+3\n",
        "        )\n",
        "        return sch\n",
        "\n",
        "    def configure_scheduler_after_epoch(self):\n",
        "        return None\n",
        "\n",
        "    def epoch_metrics(self, outputs, targets):\n",
        "        return metrics.roc_auc_score(targets, outputs)\n",
        "\n",
        "    def monitor_metrics(self, outputs, targets):\n",
        "        outputs = outputs.cpu().detach().numpy()\n",
        "        targets = targets.cpu().detach().numpy()\n",
        "        if len(np.unique(targets)) > 1: \n",
        "            roc_auc = metrics.roc_auc_score(targets, outputs)\n",
        "        else: roc_auc = 1.0\n",
        "        return roc_auc\n",
        "\n",
        "    def train_one_step(self, inputs, targets):\n",
        "        inputs = inputs.to(self.device, non_blocking=True)\n",
        "        targets = targets.to(self.device, non_blocking=True)\n",
        "        inputs, targets_a, targets_b, lam = mixup_data(inputs, \n",
        "                                                      targets,\n",
        "                                                      alpha= CFG.mixup_alpha)\n",
        "        self.optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(True):\n",
        "            if self.fp16:\n",
        "                with torch.cuda.amp.autocast(self.fp16):\n",
        "                    outputs = self.model(inputs)\n",
        "                    #loss = self.criterion(outputs, targets.view(-1, 1))\n",
        "                    loss = mixup_criterion(self.criterion,\n",
        "                                                outputs, \n",
        "                                                targets_a.view(-1, 1),\n",
        "                                                targets_b.view(-1, 1), \n",
        "                                                lam)\n",
        "                    metrics = self.monitor_metrics(outputs, targets)\n",
        "                self.scaler.scale(loss).backward()\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "            else:\n",
        "                outputs = self(inputs)\n",
        "                metrics = self.monitor_metrics(outputs, targets)\n",
        "                loss = self.criterion(outputs, targets.view(-1, 1))\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            if self.scheduler_after_step:\n",
        "                self.scheduler_after_step.step()\n",
        "        return outputs, loss, metrics\n",
        "\n",
        "    def validate_one_step(self, inputs, targets = None):\n",
        "        inputs = inputs.to(self.device, non_blocking=True)\n",
        "        if targets is not None:\n",
        "            targets = targets.to(self.device, non_blocking=True)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, targets.view(-1, 1))\n",
        "                metrics = self.monitor_metrics(outputs, targets)\n",
        "            return outputs, loss, metrics\n",
        "        else:\n",
        "            outputs = self(inputs)\n",
        "            return outputs, None, None\n",
        "\n",
        "    def predict_one_step(self, inputs):\n",
        "        outputs, _, _ = self.validate_one_step(inputs)\n",
        "        return outputs\n",
        "        \n",
        "    def train_one_epoch(self, data_loader):\n",
        "        self.model.train()\n",
        "        running_loss, running_metrics = AverageMeter(), AverageMeter()\n",
        "        tk0 = tqdm(data_loader, total=len(data_loader), position = 0, leave = True)\n",
        "        for b_idx, (inputs, targets) in enumerate(tk0):\n",
        "            preds_one_batch, loss, metrics = self.train_one_step(inputs, targets)\n",
        "            running_loss.update(loss.item(), data_loader.batch_size)\n",
        "            running_metrics.update(metrics, data_loader.batch_size)\n",
        "            current_lr = self.optimizer.param_groups[0]['lr'] \n",
        "            wandb.log({\n",
        "                \"train/step\" : b_idx,\n",
        "                \"train/loss_step\": running_loss.avg,\n",
        "                \"lr\": current_lr \n",
        "                })\n",
        "            tk0.set_postfix(train_loss=running_loss.avg, train_step_metrics = running_metrics.avg, stage=\"train\", lr = current_lr)\n",
        "        if self.scheduler_after_epoch:\n",
        "            self.scheduler_after_epoch.step()\n",
        "        tk0.close()\n",
        "        return running_loss.avg\n",
        "\n",
        "    def validate_one_epoch(self, data_loader):\n",
        "        self.model.eval()\n",
        "        running_loss, running_metrics = AverageMeter(), AverageMeter()\n",
        "        preds_list = []\n",
        "        tk0 = tqdm(data_loader, total=len(data_loader), position = 0, leave = True)\n",
        "        for b_idx, (inputs, targets) in enumerate(tk0):\n",
        "            preds_one_batch, loss, metrics = self.validate_one_step(inputs, targets)\n",
        "            preds_list.append(preds_one_batch.cpu().detach().numpy())\n",
        "            running_loss.update(loss.item(), data_loader.batch_size)\n",
        "            running_metrics.update(metrics, data_loader.batch_size)\n",
        "            tk0.set_postfix(valid_loss = running_loss.avg, validate_step_metrics = running_metrics.avg, stage=\"validation\")\n",
        "            wandb.log({\n",
        "                \"valid/step\" : b_idx,\n",
        "                \"valid/metric_step\" : running_metrics.avg,\n",
        "                \"valid/loss\": running_loss.avg, \n",
        "                })\n",
        "        preds_arr = np.concatenate(preds_list)\n",
        "        valid_metric_val = self.epoch_metrics(preds_arr, self.valid_targets)\n",
        "        tk0.close()\n",
        "        return valid_metric_val, running_loss.avg\n",
        "\n",
        "    def predict(\n",
        "        self,\n",
        "        dataset,\n",
        "        batch_size = 16,\n",
        "        num_workers = 8,\n",
        "    ):\n",
        "        self.model.eval()\n",
        "        self.test_loader =  torch.utils.data.DataLoader(\n",
        "            dataset = test_dataset, \n",
        "            batch_size = batch_size,\n",
        "            shuffle = False, \n",
        "            num_workers= num_workers,\n",
        "            drop_last = False,\n",
        "            pin_memory = True\n",
        "        )\n",
        "        preds_list = []\n",
        "        tk0 = tqdm(data_loader, total=len(self.test_loader), position = 0, leave = True)\n",
        "        for b_idx, (inputs, targets) in enumerate(tk0):\n",
        "            preds_one_batch = self.predict_one_step(inputs, targets)\n",
        "            preds_list.append(preds_one_batch.cpu().detach().numpy())\n",
        "            tk0.set_postfix(stage=\"inference\")\n",
        "        tk0.close()\n",
        "        preds_arr = np.concatenate(preds_list)\n",
        "        return preds_arr\n",
        "\n",
        "    def save(self, model_path):\n",
        "        model_state_dict = self.state_dict()\n",
        "        if self.optimizer is not None:\n",
        "            opt_state_dict = self.optimizer.state_dict()\n",
        "        else:\n",
        "            opt_state_dict = None\n",
        "        if self.scheduler_after_step is not None:\n",
        "            sch_state_dict_after_step = self.scheduler_after_step.state_dict()\n",
        "        else:\n",
        "            sch_state_dict_after_step = None\n",
        "        if self.scheduler_after_epoch is not None:\n",
        "            sch_state_dict_after_epoch = self.scheduler_after_epoch.state_dict()\n",
        "        else:\n",
        "            sch_state_dict_after_epoch = None\n",
        "        model_dict = {}\n",
        "        model_dict[\"state_dict\"] = model_state_dict\n",
        "        model_dict[\"optimizer\"] = opt_state_dict\n",
        "        model_dict[\"scheduler_after_step\"] = sch_state_dict_after_step\n",
        "        model_dict[\"scheduler_after_epoch\"] = sch_state_dict_after_epoch\n",
        "        model_dict[\"epoch\"] = self.current_epoch\n",
        "        model_dict[\"fp16\"] = self.fp16\n",
        "        model_dict[\"multiple_GPU\"] = self.multiple_GPU\n",
        "        torch.save(model_dict, model_path)\n",
        "\n",
        "    def load(self, model_path):\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        if next(self.model.parameters()).device != self.device:\n",
        "            self.to(self.device)\n",
        "        model_dict = torch.load(model_path, map_location=torch.device(device))\n",
        "        self.load_state_dict(model_dict[\"state_dict\"])\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        cfg,\n",
        "        epochs = 5,\n",
        "        checkpoint_save_path = '',\n",
        "        mode = 'max',\n",
        "        patience = 10,\n",
        "        delta = 0.001,\n",
        "    ):\n",
        "        set_seed(CFG.seed)\n",
        "        self._init_wandb(cfg)\n",
        "        path_directory = Path(checkpoint_save_path)\n",
        "        if mode == 'max':\n",
        "            current_best_valid_metrics = -float('inf')\n",
        "        else:\n",
        "            current_best_valid_metrics= float('inf')\n",
        "        early_stopping_counter = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_loss = self.train_one_epoch(self.train_loader)\n",
        "            if valid_dataset:\n",
        "                valid_metrics, valid_loss = self.validate_one_epoch(self.valid_loader)\n",
        "                # Early Stopping and save at the check points.\n",
        "                if mode == 'max':\n",
        "                    if valid_metrics < current_best_valid_metrics + delta:\n",
        "                        early_stopping_counter += 1\n",
        "                        print(f'EarlyStopping counter: {early_stopping_counter} out of {patience}')\n",
        "                        if early_stopping_counter >= patience: break\n",
        "                    else:\n",
        "                        print(f\"Validation score improved ({current_best_valid_metrics} --> {valid_metrics}). Saving the check point!\")\n",
        "                        current_best_validmetrics= valid_metrics\n",
        "                        self.save(checkpoint_save_path / f\"{cfg.pretrained_model_name}_epoch{epoch}.cpt\" )\n",
        "                else:\n",
        "                    if valid_metrics > current_best_valid_metrics - delta:\n",
        "                        early_stopping_counter += 1\n",
        "                        print(f'EarlyStopping counter: {early_stopping_counter} out of {patience}')\n",
        "                        if early_stopping_counter >= patience: break\n",
        "                    else:\n",
        "                        print(f\"Validation score improved ({current_best_valid_metrics} --> {valid_metrics}). Saving the check point!\")\n",
        "                        current_best_valid_metrics = valid_metrics\n",
        "                        self.save(checkpoint_save_path / f\"{cfg.pretrained_model_name}_epoch{epoch}.cpt\" )\n",
        "                        \n",
        "            #writer.add_scalar(\"Loss/train\", 1.0, epoch)\n",
        "            print(f'epoch: {epoch}, validate_epoch_metrics : {valid_metrics}')\n",
        "            wandb.log({\n",
        "                \"epoch\" : epoch,\n",
        "                \"train/loss\" : train_loss,\n",
        "                \"valid/loss\" : valid_loss,\n",
        "                \"valid/metric\" : valid_metrics,\n",
        "                })\n",
        "        wandb.finish()\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALlSrf3BzGB9"
      },
      "source": [
        "for fold_cnt, (train_index, test_index) in enumerate(skf.split(X, Y), 1):\n",
        "    train_images, valid_images = X[train_index], X[train_index]\n",
        "    train_targets, valid_targets = Y[train_index], Y[test_index]\n",
        "\n",
        "    train_dataset = ClassificationDataset(\n",
        "        image_paths=train_images, \n",
        "        targets=train_targets, \n",
        "        transform = train_aug\n",
        "    )\n",
        "    valid_dataset = ClassificationDataset(\n",
        "        image_paths=valid_images, \n",
        "        targets=valid_targets, \n",
        "        transform = None\n",
        "    )\n",
        "    model = BasicNN()\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model = model,\n",
        "        train_dataset = train_dataset,\n",
        "        valid_dataset = valid_dataset,\n",
        "        valid_targets = valid_targets,\n",
        "        train_batchsize = CFG.batch_size,\n",
        "        valid_batchsize = CFG.batch_size,\n",
        "        num_workers = CFG.num_workers,\n",
        "        fp16 = CFG.fp16,\n",
        "    )\n",
        "\n",
        "    trainer.fit(\n",
        "        cfg = CFG,\n",
        "        epochs = CFG.epochs,\n",
        "        checkpoint_save_path = CFG.checkpoint_path,\n",
        "        mode = CFG.patience_mode,\n",
        "        patience = CFG.patience,\n",
        "        delta = CFG.delta\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}